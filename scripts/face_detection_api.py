from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import numpy as np
import cv2
from tensorflow.keras.models import load_model
import time
import threading
import asyncio
from typing import Dict, Any
import os

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒãƒ¼ãƒˆã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5001ï¼‰
API_PORT = int(os.getenv("API_PORT", 5001))
API_HOST = os.getenv("API_HOST", "0.0.0.0")

app = FastAPI(title="Smile Detection API", version="1.0.0")

# CORSè¨­å®š - Next.jsã®ãƒãƒ¼ãƒˆã«å¯¾å¿œ
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",  # Next.jsé–‹ç™ºã‚µãƒ¼ãƒãƒ¼
        "http://127.0.0.1:3000",
        "http://localhost:3001",  # ä»£æ›¿ãƒãƒ¼ãƒˆ
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydanticãƒ¢ãƒ‡ãƒ«
class InitResponse(BaseModel):
    success: bool
    message: str = ""

class DetectionResponse(BaseModel):
    faceDetected: bool
    smiling: bool
    confidence: float

class StatsResponse(BaseModel):
    totalTime: float
    faceTime: float
    smileTime: float
    engagement: float

class StatusResponse(BaseModel):
    modelsLoaded: bool
    detecting: bool

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
model = None
face_cascade = None
detection_active = False
detection_thread = None
current_stats = {
    'totalTime': 0.0,
    'faceTime': 0.0,
    'smileTime': 0.0,
    'engagement': 0.0
}
current_detection = {
    'faceDetected': False,
    'smiling': False,
    'confidence': 0.0
}

# æ¤œå‡ºå¤‰æ•°
face_detected_time = 0.0
smile_detected_time = 0.0
start_time = 0.0
last_frame_time = 0.0
IMG_SIZE = 64

def initialize_models():
    """ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã™ã‚‹é–¢æ•°"""
    global model, face_cascade
    try:
        # è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ« "model.keras" ã‚’èª­ã¿è¾¼ã¿
        model = load_model('model.keras')
        # HAAR cascadesã‚’ä½¿ç”¨ã—ãŸé¡”æ¤œå‡ºå™¨
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        return True
    except Exception as e:
        print(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def detection_loop():
    """æ¤œå‡ºãƒ«ãƒ¼ãƒ—é–¢æ•°ï¼ˆã‚ãªãŸã®ã‚ªãƒªã‚¸ãƒŠãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ãƒ™ãƒ¼ã‚¹ã«ï¼‰"""
    global detection_active, face_detected_time, smile_detected_time, start_time, last_frame_time
    global current_stats, current_detection
    
    # ã‚¦ã‚§ãƒ–ã‚«ãƒ¡ãƒ©ã‚’é–‹ã
    cap = cv2.VideoCapture(0)
    
    # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
    face_detected_time = 0.0
    smile_detected_time = 0.0
    start_time = time.time()
    last_frame_time = time.time()
    
    while detection_active:
        # ã‚¦ã‚§ãƒ–ã‚«ãƒ¡ãƒ©ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
        ret, frame = cap.read()
        
        if not ret:
            continue
            
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒç™½é»’ã§è¨“ç·´ã•ã‚Œã¦ã„ã‚‹ãŸã‚ï¼‰
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # é¡”ã‚’æ¤œå‡º
        faces = face_cascade.detectMultiScale(gray, 1.1, 4)
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ æ™‚é–“ã‚’è¨ˆç®—
        current_time = time.time()
        frame_time = current_time - last_frame_time
        last_frame_time = current_time
        
        face_detected = len(faces) > 0
        smiling = False
        confidence = 0.0
        
        if face_detected:
            face_detected_time += frame_time
            
            for (x, y, w, h) in faces:
                # é¡”é ˜åŸŸã‚’æŠ½å‡º
                face_roi = gray[y:y+h, x:x+w]
                try:
                    # ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚º
                    face_resized = cv2.resize(face_roi, (IMG_SIZE, IMG_SIZE))
                    # å€¤ã‚’æ­£è¦åŒ–ã—ã¦(0,1)ã®ç¯„å›²ã«ã™ã‚‹
                    face_normalized = face_resized.astype("float32") / 255.0
                    face_input = np.expand_dims(face_normalized, axis=(0, -1))
                    
                    # ç¬‘é¡”ã®ç¢ºç‡ã‚’å–å¾—
                    prediction = model.predict(face_input, verbose=0)[0][0]
                    confidence = float(prediction)
                    
                    if prediction > 0.10:  # ç¬‘é¡”ã®é–¾å€¤
                        smile_detected_time += frame_time
                        smiling = True
                        
                except Exception as e:
                    print("é¡”ã®å‰å‡¦ç†ã«å¤±æ•—:", e)
                    
                break  # æœ€åˆã®é¡”ã®ã¿å‡¦ç†
        
        # ç¾åœ¨ã®æ¤œå‡ºçµæœã‚’æ›´æ–°
        current_detection = {
            'faceDetected': face_detected,
            'smiling': smiling,
            'confidence': confidence
        }
        
        # çµ±è¨ˆã‚’æ›´æ–°
        total_time = current_time - start_time
        engagement = (smile_detected_time / face_detected_time * 100) if face_detected_time > 0 else 0
        
        current_stats = {
            'totalTime': total_time,
            'faceTime': face_detected_time,
            'smileTime': smile_detected_time,
            'engagement': engagement
        }
        
        # CPUä½¿ç”¨é‡ã‚’æŠ‘ãˆã‚‹ãŸã‚ã®å°ã•ãªé…å»¶
        time.sleep(0.1)
    
    cap.release()

@app.post("/api/initialize", response_model=InitResponse)
async def initialize():
    """ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–"""
    success = initialize_models()
    if success:
        return InitResponse(success=True, message="ãƒ¢ãƒ‡ãƒ«ãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
    else:
        raise HTTPException(status_code=500, detail="ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")

@app.post("/api/start-detection", response_model=Dict[str, bool])
async def start_detection():
    """æ¤œå‡ºã‚’é–‹å§‹"""
    global detection_active, detection_thread
    
    if model is None or face_cascade is None:
        raise HTTPException(status_code=400, detail="ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    if not detection_active:
        detection_active = True
        detection_thread = threading.Thread(target=detection_loop)
        detection_thread.start()
        return {"success": True}
    
    raise HTTPException(status_code=400, detail="æ¤œå‡ºã¯æ—¢ã«ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã§ã™")

@app.post("/api/stop-detection", response_model=Dict[str, bool])
async def stop_detection():
    """æ¤œå‡ºã‚’åœæ­¢"""
    global detection_active, detection_thread
    
    detection_active = False
    if detection_thread:
        detection_thread.join()
    
    return {"success": True}

@app.get("/api/stats", response_model=StatsResponse)
async def get_stats():
    """çµ±è¨ˆã‚’å–å¾—"""
    return StatsResponse(**current_stats)

@app.get("/api/detection", response_model=DetectionResponse)
async def get_detection():
    """ç¾åœ¨ã®æ¤œå‡ºçµæœã‚’å–å¾—"""
    return DetectionResponse(**current_detection)

@app.get("/api/status", response_model=StatusResponse)
async def get_status():
    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
    return StatusResponse(
        modelsLoaded=model is not None and face_cascade is not None,
        detecting=detection_active
    )

@app.get("/")
async def root():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {"message": "Smile Detection API", "status": "running", "port": API_PORT}

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ Smile Detection API ã‚’èµ·å‹•ä¸­...")
    print(f"ğŸ“± API: http://localhost:{API_PORT}")
    print(f"ğŸ“– Docs: http://localhost:{API_PORT}/docs")
    print("â¹ï¸  åœæ­¢ã™ã‚‹ã«ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„")
    print("-" * 50)
    
    uvicorn.run(
        "face_detection_api:app",
        host=API_HOST,
        port=API_PORT,
        reload=False,
        log_level="info"
    )
